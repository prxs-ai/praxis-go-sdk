llm_agent:
  enabled: true
  provider: "openai"
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-4o-mini"
  max_tokens: 4096
  temperature: 0.1
  timeout: 30s
  
  function_calling:
    strict_mode: true
    max_parallel_calls: 5
    tool_timeout: 15s
    
  caching:
    enabled: true
    ttl: 300s
    max_size: 1000
    
  rate_limiting:
    requests_per_minute: 60
    tokens_per_minute: 100000

tool_discovery:
  auto_discover_remote: true
  refresh_interval: 60s
  cache_remote_tools: true
  discovery_timeout: 10s

logging:
  level: "info"
  format: "json"
  enable_request_logging: true
  enable_tool_logging: true
