agent:
  name: "praxis-agent-3"
  version: "1.0.0"
  description: "Praxis Agent 3 with Dagger tools"
  url: "http://localhost:8002"
  shared_dir: "./shared"

  external_mcp_endpoints: []

  tools:
    - name: "image_resizer"
      description: "Resize images locally using Python + Pillow"
      engine: "dagger"
      params:
        - name: "input_path"
          type: "string"
          description: "Path to input image in shared folder"
          required: "true"
        - name: "output_path"
          type: "string"
          description: "Path to output image in shared folder"
          required: "true"
        - name: "width"
          type: "number"
          description: "Target width"
          required: "false"
        - name: "height"
          type: "number"
          description: "Target height"
          required: "false"
      engineSpec:
        image: "python:3.11-slim"
        command: ["sh", "-c", "pip install pillow && python /shared/resize_image.py"]
        mounts:
          ./shared: /shared

    - name: "telegram_poster"
      description: "Post messages to Telegram channels"
      engine: "dagger"
      params:
        - name: "message"
          type: "string"
          description: "Message to post"
          required: "true"
        - name: "channel"
          type: "string"
          description: "Channel ID (optional)"
          required: "false"
      engineSpec:
        image: "python:3.11-slim"
        command: ["sh", "-c", "pip install requests && python /shared/telegram_post.py"]
        mounts:
          ./shared: /shared
        env_passthrough: ["TELEGRAM_BOT_TOKEN", "TELEGRAM_CHANNEL_ID"]

p2p:
  enabled: true
  port: 4003
  secure: false
  rendezvous: "praxis-network"
  enable_mdns: true
  enable_dht: true
  bootstrap_nodes: []

http:
  enabled: true
  port: 8002
  host: "0.0.0.0"

mcp:
  enabled: true
  servers: []
  limits:
    max_concurrent_requests: 10
    request_timeout_ms: 30000
    max_response_size_bytes: 10485760
    max_servers_per_node: 5
    connection_pool_size: 10
    retry_attempts: 3
    retry_backoff_ms: 1000
  log_level: "info"

llm:
  enabled: false
  provider: "openai"
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-4o-mini"
  max_tokens: 2000
  temperature: 0.7
  request_timeout: 30
  cache_enabled: true
  cache_ttl: 600
  tools_enabled: true

logging:
  level: "debug"
  format: "text"
  output: "stdout"

